{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# general\n",
    "import os\n",
    "import glob\n",
    "import datetime as dt\n",
    "import json\n",
    "# data \n",
    "import xarray as xr \n",
    "from sublimpy import utils, variables, tidy, turbulence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from act import discovery, plotting\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import add_metpy_logo, SkewT\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import cufflinks as cf\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "# helper tools\n",
    "from scripts.get_sail_data import get_sail_data\n",
    "from scripts.helper_funcs import create_windrose_df, simple_sounding, mean_sounding\n",
    "import scripts.helper_funcs as hf\n",
    "from metpy import calc, units\n",
    "# make plotly work \n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "# run nc deep_clean\n",
    "import nctoolkit as nc\n",
    "nc.deep_clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load ARM credentials\n",
    "def load_arm_credentials(credential_path):\n",
    "    with open(credential_path, 'r') as f:\n",
    "        credentials = json.load(f)\n",
    "    return credentials\n",
    "# Location of ARM credentials\n",
    "credential_path = '/home/dlhogan/.act_config.json'\n",
    "credentials = load_arm_credentials(credential_path)\n",
    "# api token and username for ARM\n",
    "api_username = credentials.get('username')\n",
    "api_token = credentials.get('token')\n",
    "\n",
    "sail_datastream_dict = {\n",
    "    \"tropoe\":\"guctropoeM1.c1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_22 = ('20211201','20220401')\n",
    "winter_23 = ('20221201','20230401')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the location of the data folder where this data will be stored\n",
    "winter_22_folder = 'winter_21_22'\n",
    "winter_23_folder = 'winter_22_23'\n",
    " # change to location of data folder on your machine\n",
    "storage_directory = f'/storage/dlhogan/synoptic_sublimation/'\n",
    "# create a sail_data folder if it does not exist\n",
    "if not os.path.exists(os.path.join(storage_directory,'sail_data')):\n",
    "    os.makedirs(os.path.join(storage_directory,'sail_data'))\n",
    "# create a folder for the event if it does not exist\n",
    "if not os.path.exists(os.path.join(storage_directory,'sail_data',winter_22_folder)):\n",
    "    os.makedirs(os.path.join(storage_directory,'sail_data',winter_22_folder))\n",
    "# create a folder for the event if it does not exist\n",
    "if not os.path.exists(os.path.join(storage_directory,'sail_data',winter_23_folder)):\n",
    "    os.makedirs(os.path.join(storage_directory,'sail_data',winter_23_folder))\n",
    "    # make a radiosonde folder if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tropoe_20211201_20220401.nc already exists\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "# load in the winter 22 data\n",
    "sail_winter_22_folder = os.path.join(storage_directory,'sail_data',winter_22_folder)\n",
    "# create empty data dictionary\n",
    "w22_data_loc_dict = {}\n",
    "# Iterate through the dictionary and pull the data for each datastream\n",
    "for k,v in sail_datastream_dict.items():\n",
    "\n",
    "    if (os.path.exists(f'{sail_winter_22_folder}/{k}_{winter_22[0]}_{winter_22[1]}.nc')): \n",
    "        print(f'{k}_{winter_22[0]}_{winter_22[1]}.nc already exists')\n",
    "        print('-------------------')\n",
    "        # add the filename to the dictionary which can be used if we want to load the data\n",
    "        w22_data_loc_dict[k] = os.path.join(sail_winter_22_folder,f'{k}_{winter_22[0]}_{winter_22[1]}.nc')\n",
    "        continue\n",
    "    else:\n",
    "        # explicitly download radiosonde data because they are a lot easier to process and think about when in individual files\n",
    "        ds = get_sail_data(api_username,\n",
    "                        api_token,\n",
    "                        v,\n",
    "                        startdate=winter_22[0],\n",
    "                        enddate=winter_22[1])\n",
    "        ds.to_netcdf(f'{sail_winter_22_folder}/{k}_{winter_22[0]}_{winter_22[1]}.nc')\n",
    "        w22_data_loc_dict[k] = os.path.join(sail_winter_22_folder,f'{k}_{winter_22[0]}_{winter_22[1]}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the data\n",
    "tropoe_w22 = xr.open_dataset(w22_data_loc_dict['tropoe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tropoe_20221201_20230401.nc already exists\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "# load in the winter 23 data\n",
    "sail_winter_23_folder = os.path.join(storage_directory,'sail_data',winter_23_folder)\n",
    "# create empty data dictionary\n",
    "w23_data_loc_dict = {}\n",
    "# Iterate through the dictionary and pull the data for each datastream\n",
    "for k,v in sail_datastream_dict.items():\n",
    "\n",
    "    if (os.path.exists(f'{sail_winter_23_folder}/{k}_{winter_23[0]}_{winter_23[1]}.nc')): \n",
    "        print(f'{k}_{winter_23[0]}_{winter_23[1]}.nc already exists')\n",
    "        print('-------------------')\n",
    "        # add the filename to the dictionary which can be used if we want to load the data\n",
    "        w23_data_loc_dict[k] = os.path.join(sail_winter_23_folder,f'{k}_{winter_23[0]}_{winter_23[1]}.nc')\n",
    "        continue\n",
    "    else:\n",
    "        # explicitly download radiosonde data because they are a lot easier to process and think about when in individual files\n",
    "        ds = get_sail_data(api_username,\n",
    "                        api_token,\n",
    "                        v,\n",
    "                        startdate=winter_23[0],\n",
    "                        enddate=winter_23[1])\n",
    "        ds.to_netcdf(f'{sail_winter_23_folder}/{k}_{winter_23[0]}_{winter_23[1]}.nc')\n",
    "        w23_data_loc_dict[k] = os.path.join(sail_winter_23_folder,f'{k}_{winter_23[0]}_{winter_23[1]}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sublime_synoptics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
